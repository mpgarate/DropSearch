# The maximum number of pages to be crawled from a given startUrl.
# run tests with 100; practical maximum seems to be about 5000 depending on
# hardware
maxCrawlPages=2000

# Title weight figured in the relevance of a term -> document pair
# see edu.nyu.mpgarate.dropsearch.crawl.Extractor:132
titleWeight=0.1

# after crawling x pages, trigger a background refresh of the pagerank scores
# see edu.nyu.mpgarate.dropsearch.crawl.Crawler:110
pageRankRefreshRate=100

# base amount added to all pagerank scores
# see edu.nyu.mpgarate.dropsearch.algorithm.SearchResultRelevanceCalc
pageRankOffset=0.000015

# pageRank scores are multiplied by this factor
# see edu.nyu.mpgarate.dropsearch.algorithm.SearchResultRelevanceCalc
pageRankWeight=0.6

# term -> document pairings are multipled by this factor
# see edu.nyu.mpgarate.dropsearch.algorithm.SearchResultRelevanceCalc
keywordsRate=0.4

# the system is designed to be able to run a few crawl/search environments at
# once, but for memory and cpu purposes here we will use 1 for the demo
# see edu.nyu.mpgarate.dropsearch.SearchEngineFactory:13
maxActiveSearchEngines=2

# In milliseconds, how long the crawler must wait between http requests to
# the same server. Pages cached in the database do not have to wait.
# see edu.nyu.mpgarate.dropsearch.crawl.Crawler:161
crawlPolitenessDelay=1000

# How many results should be returned for a query?
# see edu.nyu.mpgarate.dropsearch.retrieve.RetrievalEngine:166
resultCount=25
